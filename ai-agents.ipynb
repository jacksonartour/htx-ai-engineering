{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "738b87cd",
   "metadata": {},
   "source": [
    "# 0. load imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82f9204b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\python313\\lib\\site-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: langchain in c:\\python313\\lib\\site-packages (from -r requirements.txt (line 2)) (0.3.27)\n",
      "Requirement already satisfied: langgraph in c:\\python313\\lib\\site-packages (from -r requirements.txt (line 3)) (0.6.8)\n",
      "Requirement already satisfied: pydantic in c:\\python313\\lib\\site-packages (from -r requirements.txt (line 4)) (2.11.9)\n",
      "Requirement already satisfied: python-dotenv in c:\\python313\\lib\\site-packages (from -r requirements.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: langchain_google_genai in c:\\python313\\lib\\site-packages (from -r requirements.txt (line 6)) (2.1.12)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\python313\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\python313\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\python313\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (0.4.31)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\python313\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\python313\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python313\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\python313\\lib\\site-packages (from langgraph->-r requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in c:\\python313\\lib\\site-packages (from langgraph->-r requirements.txt (line 3)) (0.6.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\python313\\lib\\site-packages (from langgraph->-r requirements.txt (line 3)) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\python313\\lib\\site-packages (from langgraph->-r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python313\\lib\\site-packages (from pydantic->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\python313\\lib\\site-packages (from pydantic->-r requirements.txt (line 4)) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\python313\\lib\\site-packages (from pydantic->-r requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\python313\\lib\\site-packages (from pydantic->-r requirements.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage<1,>=0.7 in c:\\python313\\lib\\site-packages (from langchain_google_genai->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: filetype<2,>=1.2 in c:\\python313\\lib\\site-packages (from langchain_google_genai->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r requirements.txt (line 6)) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\python313\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r requirements.txt (line 6)) (2.41.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\python313\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r requirements.txt (line 6)) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\python313\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r requirements.txt (line 6)) (6.32.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 2)) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 2)) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\riley\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\python313\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph->-r requirements.txt (line 3)) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\python313\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph->-r requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\python313\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph->-r requirements.txt (line 3)) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 2)) (0.25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python313\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python313\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python313\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python313\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\python313\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 2)) (3.2.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\python313\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r requirements.txt (line 6)) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r requirements.txt (line 6)) (1.75.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r requirements.txt (line 6)) (1.75.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r requirements.txt (line 6)) (6.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r requirements.txt (line 6)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r requirements.txt (line 6)) (4.9.1)\n",
      "Requirement already satisfied: anyio in c:\\python313\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph->-r requirements.txt (line 3)) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python313\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph->-r requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\python313\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\python313\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\python313\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r requirements.txt (line 6)) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python313\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph->-r requirements.txt (line 3)) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24715f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMINI_API_KEY loaded successfully\n",
      "Imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.schema import BaseMessage, HumanMessage, SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Get API key\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    print(\"Warning: GEMINI_API_KEY not found in environment variables\")\n",
    "    print(\"Please make sure to set your API key in the .env file\")\n",
    "else:\n",
    "    print(\"GEMINI_API_KEY loaded successfully\")\n",
    "\n",
    "print(\"Imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "251ea607",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.0-flash\", \n",
    "        temperature=0, \n",
    "        api_key=GEMINI_API_KEY,\n",
    "        convert_system_message_to_human=True\n",
    "    )\n",
    "    print(\"LLM initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing LLM: {e}\")\n",
    "    llm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76a4d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_MESSAGE = \"You are a helpful assistant that extracts financial data from documents.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0759a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 30.558478021s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 30\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 28.496937361s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 57.374076999s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 49.328162418s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 33.263873142s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 33\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm doing well, thank you for asking.\n",
      "\n",
      "I'm ready to help you extract financial data from your documents. How can I assist you today? You can upload a file, paste the text, or just describe the information you need.\n"
     ]
    }
   ],
   "source": [
    "res = llm.invoke([\n",
    "        SystemMessage(content=DEFAULT_SYSTEM_MESSAGE),\n",
    "        HumanMessage(content=\"Hey how are you?\")\n",
    "    ])\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6af501",
   "metadata": {},
   "source": [
    "# 1. Document extraction & Prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72f2f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE_FILE_NAME = \"fy2024_analysis_of_revenue_and_expenditure.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c9c050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "class FinancialExtractionOutput(BaseModel):\n",
    "    \"\"\"Structured output for financial data extraction from the PDF\"\"\"\n",
    "    \n",
    "    corporate_income_tax_2024: Optional[float] = Field(\n",
    "        description=\"Amount of Corporate Income Tax in 2024 (in millions or appropriate unit)\"\n",
    "    )\n",
    "    \n",
    "    yoy_percentage_corp_income_tax_2024: Optional[float] = Field(\n",
    "        description=\"Year-on-year percentage difference of Corporate Income Tax in 2024\"\n",
    "    )\n",
    "    \n",
    "    total_top_ups_2024: Optional[float] = Field(\n",
    "        description=\"Total amount of top ups in 2024 (in millions or appropriate unit)\"\n",
    "    )\n",
    "    \n",
    "    operating_revenue_taxes: List[str] = Field(\n",
    "        description=\"List of taxes mentioned in the Operating Revenue section\"\n",
    "    )\n",
    "\n",
    "print(\"Imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "934aed80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINISTRY OF FINANCE \n",
      " \n",
      "5 \n",
      " \n",
      "01 Update on Financial Year 2023 \n",
      " \n",
      "1.1 \n",
      "Expected Overall Fiscal Position for FY2023  \n",
      " \n",
      "The basic deficit is revised to $5.4 billion (0.8% of GDP). After factoring in Top-\n",
      "ups to Endowment and Trust Funds of $24.3 billion, Net Investment Returns \n",
      "Contribution (NIRC) of $22.9 billion, Capitalisation of Nationally Significant \n",
      "Infrastructure of $3.5 billion, and Significant Infrastructure Government Loan \n",
      "Act (SINGA) Interest Costs and Loan Expenses of $0.2 billion, th\n"
     ]
    }
   ],
   "source": [
    "import pymupdf  \n",
    "\n",
    "with pymupdf.open(DATA_SOURCE_FILE_NAME) as doc:\n",
    "    pdf_text = {}\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        pdf_text[page_num + 1] = page.get_text()\n",
    "\n",
    "# 500 characters of page 5\n",
    "print(pdf_text[5][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791e88b",
   "metadata": {},
   "source": [
    "Separate prompts so we don't blow the context window, or exceed free tier input token limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f4c4a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for Corporate Income Tax Amount in 2024 (page 5)\n",
    "corp_income_tax_prompt = \"\"\"\n",
    "You are a financial analyst. Extract the exact amount of Corporate Income Tax for FY2024 from the following page text. \n",
    "Return only the number as a float (in millions if specified, otherwise in the unit mentioned). \n",
    "If not found, return null.\n",
    "\n",
    "PAGE TEXT:\n",
    "{page_text}\n",
    "\"\"\"\n",
    "\n",
    "# Prompt for YOY Percentage Difference of Corporate Income Tax in 2024 (page 5)\n",
    "yoy_corp_income_tax_prompt = \"\"\"\n",
    "You are a financial analyst. Extract the year-over-year percentage change of Corporate Income Tax from 2023 to 2024 from the following page text. \n",
    "Return only the percentage as a float (positive for increase, negative for decrease). \n",
    "If not found, return null.\n",
    "\n",
    "PAGE TEXT:\n",
    "{page_text}\n",
    "\"\"\"\n",
    "\n",
    "# Prompt for Total Amount of Top-ups in 2024 (page 20)\n",
    "total_top_ups_prompt = \"\"\"\n",
    "You are a financial analyst. Extract the total amount of all top-ups to endowment and trust funds for FY2024 from the following page text. \n",
    "Sum all individual top-up amounts if presented separately. Return only the total as a float (in millions if specified). \n",
    "If not found, return null.\n",
    "\n",
    "PAGE TEXT:\n",
    "{page_text}\n",
    "\"\"\"\n",
    "\n",
    "# Prompt for List of Taxes in Operating Revenue Section (pages 5-6)\n",
    "operating_revenue_taxes_prompt = \"\"\"\n",
    "You are a financial analyst. Identify all types of taxes mentioned in the \"Operating Revenue\" section from the following page text. \n",
    "Return a list of the exact tax names as strings. If not found, return an empty list.\n",
    "\n",
    "PAGE TEXT:\n",
    "{page_text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3bdb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_financial_data_from_pdf(pdf_text: dict, llm) -> FinancialExtractionOutput:\n",
    "    \"\"\"\n",
    "    Extracts financial data from specific pages of the PDF using LLM prompts.\n",
    "    Args:\n",
    "        pdf_text (dict): Dictionary mapping page numbers to page text.\n",
    "        llm: The language model instance to use for extraction.\n",
    "    Returns:\n",
    "        FinancialExtractionOutput: Structured extraction result.\n",
    "    \"\"\"\n",
    "    # Corporate Income Tax Amount for 2024 (page 5)\n",
    "    corp_income_tax_resp = llm.invoke([\n",
    "        SystemMessage(content=DEFAULT_SYSTEM_MESSAGE),\n",
    "        HumanMessage(content=corp_income_tax_prompt.format(page_text=pdf_text[5]))\n",
    "    ]).content\n",
    "    print(f\"Corporate Income Tax Response: {corp_income_tax_resp}\")\n",
    "    try:\n",
    "        corporate_income_tax_2024 = float(re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", corp_income_tax_resp)[0])\n",
    "    except Exception:\n",
    "        corporate_income_tax_2024 = None\n",
    "\n",
    "    # YOY Percentage Difference of Corporate Income Tax in 2024 (page 5)\n",
    "    yoy_corp_income_tax_resp = llm.invoke([\n",
    "        SystemMessage(content=DEFAULT_SYSTEM_MESSAGE),\n",
    "        HumanMessage(content=yoy_corp_income_tax_prompt.format(page_text=pdf_text[5]))\n",
    "    ]).content\n",
    "    print(f\"YOY Corporate Income Tax Response: {yoy_corp_income_tax_resp}\")\n",
    "    try:\n",
    "        yoy_percentage_corp_income_tax_2024 = float(re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", yoy_corp_income_tax_resp)[0])\n",
    "    except Exception:\n",
    "        yoy_percentage_corp_income_tax_2024 = None\n",
    "\n",
    "    # Total Amount of Top-ups in 2024 (page 20)\n",
    "    total_top_ups_resp = llm.invoke([\n",
    "        SystemMessage(content=DEFAULT_SYSTEM_MESSAGE),\n",
    "        HumanMessage(content=total_top_ups_prompt.format(page_text=pdf_text[20]))\n",
    "    ]).content\n",
    "    print(f\"Total Top-ups Response: {total_top_ups_resp}\")\n",
    "    try:\n",
    "        total_top_ups_2024 = float(re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", total_top_ups_resp)[0])\n",
    "    except Exception:\n",
    "        total_top_ups_2024 = None\n",
    "\n",
    "    # List of Taxes in Operating Revenue Section (pages 5-6)\n",
    "    operating_revenue_text = pdf_text[5] + \"\\n\" + pdf_text[6]\n",
    "    operating_revenue_taxes_resp = llm.invoke([\n",
    "        SystemMessage(content=DEFAULT_SYSTEM_MESSAGE),\n",
    "        HumanMessage(content=operating_revenue_taxes_prompt.format(page_text=operating_revenue_text))\n",
    "    ]).content\n",
    "    print(f\"Operating Revenue Taxes Response: {operating_revenue_taxes_resp}\")\n",
    "    try:\n",
    "        taxes = json.loads(operating_revenue_taxes_resp)\n",
    "        if not isinstance(taxes, list):\n",
    "            raise ValueError\n",
    "        operating_revenue_taxes = taxes\n",
    "    except Exception:\n",
    "        operating_revenue_taxes = re.findall(r'\"([^\"]+)\"', operating_revenue_taxes_resp)\n",
    "\n",
    "    return FinancialExtractionOutput(\n",
    "        corporate_income_tax_2024=corporate_income_tax_2024,\n",
    "        yoy_percentage_corp_income_tax_2024=yoy_percentage_corp_income_tax_2024,\n",
    "        total_top_ups_2024=total_top_ups_2024,\n",
    "        operating_revenue_taxes=operating_revenue_taxes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89767109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 45.233754798s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 45\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 43.188858535s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 43\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m extracted_data = \u001b[43mextract_financial_data_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mextract_financial_data_from_pdf\u001b[39m\u001b[34m(pdf_text, llm)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mExtracts financial data from specific pages of the PDF using LLM prompts.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03m    FinancialExtractionOutput: Structured extraction result.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Corporate Income Tax Amount for 2024 (page 5)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m corp_income_tax_resp = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEFAULT_SYSTEM_MESSAGE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorp_income_tax_prompt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdf_text\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.content\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCorporate Income Tax Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorp_income_tax_resp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1676\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1673\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1674\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1676\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1023\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1014\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1020\u001b[39m     **kwargs: Any,\n\u001b[32m   1021\u001b[39m ) -> LLMResult:\n\u001b[32m   1022\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:840\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    838\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    839\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m         )\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    848\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1089\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1087\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1093\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1790\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m   1789\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.max_retries\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1796\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:238\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    231\u001b[39m params = (\n\u001b[32m    232\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (request := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    237\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\tenacity\\__init__.py:487\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoSleep):\n\u001b[32m    486\u001b[39m     retry_state.prepare_for_next_attempt()\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m do\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\tenacity\\nap.py:31\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(seconds)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msleep\u001b[39m(seconds: \u001b[38;5;28mfloat\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[33;03m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "extracted_data = extract_financial_data_from_pdf(pdf_text, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corporate_income_tax_2024=None yoy_percentage_corp_income_tax_2024=None total_top_ups_2024=20352.0 operating_revenue_taxes=['Operating Revenue', 'Corporate Income Tax', 'Other Taxes', 'Personal Income Tax', 'Assets Taxes', 'Betting Taxes', 'Goods and Services Tax', 'Foreign Worker Levy', 'Water Conservation Tax', 'Land Betterment Charge', 'Annual Tonnage Tax', 'Casino Taxes']\n"
     ]
    }
   ],
   "source": [
    "print(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37229002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
